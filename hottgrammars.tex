\subsection{Ranta's HoTT Grammar}

In 2014, Ranta gave an unpublished talk at the Stockholm Mathematics Seminar
\cite{aarneHott}. Fortunately the code is available, although many of the design
choices aren't documented in the grammar. This project aimed to provide a
translation like the one desired in our current work, but it took a real piece
of mathematics text as the main influence on the design of the abstract syntax.

This work took a page of text from Peter Aczel's book which more or less goes
over standard HoTT definitions and theorems. The grammar allows the translation
of the latex document in English to the same document in French, and to a pidgin
logical language. The central motivation of this grammar was to capture entirely
``real" natural language mathematics, i.e. that which was written for the
mathematician. Therefore, it isn't reminiscent of the slender abstract syntax
the type theorist adores, and sacrificed ``syntactic completeness" for
``semantic adequacy". This means that the abstract syntax is much larger and
very expressive, but it no longer becomes easy to reason about and additionally
quite ad-hoc. Another defect is that this grammar overgenerates, so producing a
unique parse from the PL side would require a significant amount of refactoring.
Nonetheless, it is presumably possible to carve a subset of the
GF HoTT abstract file to accommodate an Agda program, but one encounters rocks
as soon as one begins to dig.

In \autoref{fig:R1} one can see different syntactic presentations of a notion of
\emph{contractability}, that a space is deformable into a single point, or that a Type
is actually inhabited by a unique term. Some rendered latex taken verbatim from
Ranta's test code, compared with the translated pidgin logic code (after
refactoring of Ranta's linearization scheme) and an Agda program. We see that it was
fairly easy to get the notation for our cubicalTT grammar [ref cubicaltt].
When parsing the logical form, unfortunately, the grammar is incredibly ambiguous.

\input{latex/ContrClean}

To extend this grammar to accommodate a chapter worth of material, let alone a
book, will not just require extending the lexicon, but encountering other
syntactic phenomena that will further be difficult to compress when defining
Agda's concrete syntax. This demonstrates that to design a grammar prioritizing
\emph{semantic adequacy} and subsequently trying to incorporate \emph{syntactic
completeness} becomes a very difficult problem. Depending on the application of
the grammar, the emphasis on this axis is most assuredly a choice one should
consider up front.

The next grammar, taking an actual programming language
parser in Backus-Naur Form Converter (BNFC), GFifying it, and trying to use the
abstract syntax to model natural language, gives in some sense a dual challenge,
where the abstract syntax remains simple as in our dependently typed grammar,
but its linearizations become increasingly complex, especially when generating
natural language.

\subsection{cubicalTT Grammar}

Cubical type theories arose out of the desire to give a complete computational
interpretation to HoTT, whereby nonviolence would become a theorem rather than
an axiom \cite{cohen:hal-01378906}. The utility of this is that canonicity, the
property of an expression having a irreducible normal form, is satisfied for all
expressions. Univalence, by introducing a type without computational behavior,
means that the constructivist using Agda will be able to define terms which
don't normalize.

The origin of cubical, looking beyond simplicial models of type theory to
cubical categories instead \cite{bezem2017univalence}, gave a blueprint for a
totally new type theory which natively supports proving functional
extensionality, which is a especially important for mathematicians. The ideas of
cubical became the origin for a new series of proof assistants, cubical [cite
https://github.com/simhu/cubical] and cubicaltt [cite
https://github.com/mortberg/cubicaltt], and Cubical Agda \cite{cubicalAgda}, as
well as other in originating from Robert Constables disciples in the NuPrl
tradition [cite redprl, redtt, jonprl]. cubicalTT, which was relatively
complete, had an unambiguous BNFC grammar, more or less represents a kernel of
Agda with cubical primitives. This final grammar, which we don't as cubicalTT,
took the actual cubicalTT grammar and GFified the subset which is in the
intersection with vanilla Agda. Extending our GF version to include cubical
primitives would facilitate the extension of the work to Cubical Agda, and we
hope future endeavors will go in this direction. Cubical Agda
supports Higher Inductive Types natively and is capable of all types of new
constructions [cite stuff] not mentioned in the HoTT book, but is also
incredibly experimental, with large changes to the standard library constantly
underway as in [refer intro].

Our grammar for vanilla dependent $\Pi$-types [refer earlier section] was actually
a subset of the current cubicalTT abstract syntax. We give a brief sketch of the
algorithm to go between a BNFC grammar and a GF grammar. BNFC essentially
combines the abstract and concrete syntax, enabling a hierarchy of numbered
expressions \term{ExpN} to minimize use of parentheses. So, given m names and
choosing $Name_i$, with the accompanying rule :

$$Name_i.\; ReturnCat_{i_n} ::= s^0_{i}\;C^0_{i_0}\;...\;C^{n-1}_{i_{n-1}}\;s^n_{i}\;;$$

where string $s^i_j$ may be empty and the $k$ in the $i^{th}_k$ subscript represents the 
precedence number of a category. These precedences are indicated with a
\term{Coercions N} keyword in BNFC. We can produce the following in GF.

$$cat\; Name_i\; \bigcap\{ReturnCat_i,C^0,..., C^{n-1}\}\;;$$
$$fun\; Name_i\:{:} C^0 \rightarrow ... \rightarrow C^{n-1} \rightarrow ReturnCat_i $$
$$lincat \: \bigcap\{ReturnCat_i,C^0,..., C^{n-1}\}\;; = TermPrec$$
$$lin \; Name_i\;c^0\;... \;c^n = mkPrec(i_n,(s^0_{i}\texttt{++}usePrec(i_0+1,c^0)\texttt{++}...\texttt{++}usePrec(i_{n-1}+1,c^{n-1})\texttt{++}s^n_{i})) ;$$

where $c^j \in C^j \; \forall i,j$, and \term{usePrec} and \term{mkPrec} come
from the RGL, as seen earlier. We also note that some \term{lincat} might
actually just be strings (or something else), for it is only when a precedence
is observed that the \codeword{TermPrec} is applicable. The use of
\term{usePrec} is only applicable when $i_k$ isn't empty. Additionally, this
doesn't account for the fact that already some categories may have been
witnessed in which case we want to intersect over the whole set of rules at
once. We reiterate the examples from the simply typed lambda calculus. The BNFC
code results in the GF code immediately below.

\begin{verbatim}
--BNFC
Lam. Exp  ::= "\\" [PTele] "->" Exp ;
Fun. Exp1 ::= Exp2 "->" Exp1 ;
-- GF
cat Exp ; PTele ;
fun
  Lam : [PTele] -> Exp -> Exp ;
  Fun : Exp -> Exp -> Exp ;
lincat Exp = TermPrec ; [PTele] = Str ;
lin 
  Lam pt e = mkPrec 0 ("\\" ++ pt ++ "->" ++ usePrec 0 e) ;
  Fun = mkPrec 1 (usePrec 2 x ++ "->" ++ usePrec 1 y) ;
\end{verbatim}

This more or less elaborates exactly how to implement a programming language
with unambiguous parsing in GF. There is also a simple means of translating
lists, including BNFC's \term{separator} and \term{terminator} keywords during
the linearization process. Finally, there is a custom \term{token} keyword, and
this is perhaps the most important feature absent in GF.
Because BNFC generates Haskell code reminiscent of the PGF embedding, it would
also be possible to translate the trees directly, if parsing complexity with GF
was found to be slower than BNFC.

Most interestingly is to look at what is absent in BNFC, namely, the ability to
add records and paremeters into the linearization types generally, although
these GF features are implicitly used to encode precedence. For one could add
unique categories in GF $Exp_1,...,Exp_n$, but this would clutter the abstract
syntax with information which isn't \emph{semantically} relevant. And while the
Haskell code generated by BNFC for cubicalTT is sent through a resolver to the
\emph{actual} abstract syntax used by the type-checker and evaluator, the fact
that it parses the concrete syntax into an appropriate intermediary form is
enough for our purposes.

We give the full grammar, including examples, in the appendix \ref{cubicaltt}.

\subsubsection{Difficulties}

While our grammar certainly supports a real programming language syntax, modulo
a few quarks, linearizing to a CNL for mathematics was not implemented due to
time constraints, and the difficulties already encountered for an even simpler
programming language \ref{assoc}, namely that types and terms in dependent type
theory can be of just about any grammatical category, where we list a few :

\begin{itemize}
\item nouns, ``zero"
\item adjectives, ``prime"
\item verbs, ``add"
\item verb phrase, ``apply the function to the subset of..."
\item sentence, ``if x is odd, then y is even"
\item paragraph or more, ``suppose x. then by y we know z. hence, w. but the v
  gives additionally gives us..."
\end{itemize}

In \cite{rantaZ}, the authors, generating human readable natural language from
specifications, used a word type with many different fields for different
grammatical categories (with the same grammatical categories sometimes
accounting for multiple fields), in addition to symbolic fields. While deemed
successful by the client, it would be interesting to apply this methodology to 
cubicalTT the grammar, and see how it scales once one begins to add more
of Agda's capabilities. Their system also involved other components, like
haskell transformations, and it is uncertain how these specific approaches would
also allow for the generation of more \emph{semantically adequate} language.

Other issues encountered in this grammar were Agda's pattern matching, whereby
arguments are arranged in a matrix, as opposed to explicit cases, or \emph{splits}.
While cubicalTT allows syntax like

\begin{verbatim}
equalNat : nat -> nat -> bool = split
    zero -> split@ ( nat -> bool ) with
      zero  -> true
      suc n -> false
    suc m -> split@ ( nat -> bool ) with
      zero  -> false
      suc n -> equalNat m n
\end{verbatim}

The problem is that when linearizing a split, one cannot know how many further
splits will take place, and so going from this form to the more ``readable" Agda
code below is outside of GF's linearization capabilities - although a proof of
this fact would require advanced mathematical capabilities.

\begin{verbatim}
equalNat : nat → nat → bool
equalNat zero zero = true ; 
equalNat zero (suc n2) = false ;
equalNat (suc n1) zero = false ;
equalNat (suc n1) (suc n2) = equalNat n1 n2
\end{verbatim}

One could instead just introduce a new form of declarations in the abstract
syntax so-as to allow for \term{equalNat}, but this would require more Haskell
overhead to allow for the correct AST transformations. 

The way lists are dealt with in natural language vs. programming
languages present obstacles, because the RGL's support for lists require certain
numbers of categories in the end node, e.g. \codeword{cat[2]}, whereas our Agda
grammar may instead have \codeword{cat[1]} or \codeword{cat[0]} for the same
category, thereby require overloading of categories for the two linearization
spaces, or alternatively adding more complexity to the linearization categories.

While presented succinctly here, these obstacles were legitimate difficulties
which obliged us to test them on smaller grammars to isolate the phenomena
trying to be overcome.

\subsubsection{More advanced Agda features}

Our grammar realistically covers just a small kernel of Agda's features and
syntax. Agda supports much more, both in terms of syntactic sugar and
semantically interesting. Aside from telescopes, other syntactic sugar features
of Agda include unicode support, do notation, idiom brackets, generalized
variable declarations, and more. While require significant work to extend the 
cubicalTT grammar with these, it is doubtful
these kinds of features offer significant theoretical challenges in terms of
translation to natural language.

From the semantic side, however, Agda offers many features which extend just the kernel
of the $\Pi$, $\Sigma$, and recursive data type definitions which form the basis
of any dependent type theory. These include universes, sized types, modules,
overloading for more ad-hoc polymorphism, proof by reflection, a sort system,
higher inductive types (thanks to cubical), and many more things visible in the Agda documentation [cite agda docs].
Additionally, it has more traditional PL features, like the ability to perform
side effects or call Haskell functions. Adding any one of these not only adds
overhead to the parser, but would require lots of thought in terms of how to
these features manifest in natural language for mathematicians (and programmers).
Additionally, these features make the metatheory of Agda much more expensive to
understand, in addition to the practical implications of introducing bugs in its
implementation.

Mathematics on the other hand, doesn't often introduce more advanced ``semantic
machinery" like those listed, at least not in a way that is explicitly designed.
Perhaps idioms and conventions change, as well as generalizations, i.e. Category
Theory, offering ways of presenting ideas more succinctly, but these are merely
reflected in the presentation, not in the underlying logical formalism. The
linguistic evolution of mathematics additionally reflects some kind of
meta-changes, but not in a coherent way that is yet understood. For many
mathematicians are largely interested in proving theorems and solving problems
specific to some domain, and many mathematicians are unfamiliar with logic as a
discipline as a whole, let alone type theory.

The resolution of these meta-ideas from both the type theoretic and mathematical
perspectives is what makes this problem of translation so philosophically
intriguing, as well as intractable. We hope these observations might offer some
light when trying to examine any one of these deep and undeveloped problems.

\subsection{Comparing the Grammars}

To conclude this section, we compare the Ranta's HoTT grammar and our cubicalTT
grammar. We hope that doing so offers some final insights into how to approach
the problem of syntactic
completeness and semantic adequacy. 

cubicalTT is in some sense takes expressions as its epicenter, whereby
declarations, branches, telescopes, where expressions, and lists offer syntactic
sugar so that it becomes a minimally readable programming language. It is a
synthetic approach to writing a grammar, whereby one has an a priori idea of
what an expression syntactically should be, with the most important feature
being that it is inductively generated. It is not really concerned with
semantics per-se, because this is the job of the type-checker and evaluator.

HoTT, on the other hand, analyses real text, and decisions about the grammar are
made posterior to observing phenomena.  The grammar makes distinction between
\codeword{Formulas}, namely expressions with symbolic support for latex, 
\codeword{Framework} which allows one to construct natural language sentences,
and a \codeword{HottLexicon}. This grammar, while having some inductive notion
of what an expression is, puts the bulk of work in producing valid sentences in \codeword{Framework}.

\begin{verbatim}
cat
  Paragraph ;        -- definition, theorem, etc
  Definition ;       -- definition of a new concept
  Assumption ;       -- assumption in a proof  -- let ...
  [Assumption]{1} ;  -- list of assumptions in one sentence -- let ... and ...
  Conclusion ;       -- conclusion in a proof -- thus P
  Prop ;             -- proposition (sentence or formula) -- A is contractible
  Sort ;             -- set, type, etc corresponding to a common noun
  Ind ;              -- individual, element, corresponding to a singular term
  Fun ;              -- function with individual value
  Pred ;             -- predicate: function with proposition value -- contractible
  [Ind] ;            -- list of individual expressions   -- 1, 2 and 3
  UnivPhrase ;       -- universal noun phrase          -- for all x,y : A
  ConclusionPhrase ; -- conclusion word                -- hence
  Label ;            -- name/number of definition, theorem, etc -- Id-induction
  Title ;            -- title for theorem, definition, etc
\end{verbatim}

The distinction between individuals, propositions,
sorts, functions, and predicates also allows more nuance, but delegates the work
of deciding what category a term represents much more difficult, which makes the
possibility of having some algorithm infer the right category much more
difficult.  Additionally, 
We see that the universal phrase, the notion of a $\Pi$-type, merits semantic 
distinction in this grammar, with unique functions being assigned for all the
(observed) ways of saying it.

\begin{verbatim}
  plainUnivPhrase   : [Var] -> Sort -> UnivPhrase ;  -- for x, y : A
  eachUnivPhrase    : [Var] -> Sort -> UnivPhrase ;  -- for each x,y : A
  allUnivPhrase     : [Var] -> Sort -> UnivPhrase ;  -- for all x,y : A
  ifUnivPhrase      : [Var] -> Sort -> UnivPhrase ;  -- if x,y : A
  if_thenUnivPhrase : [Var] -> Sort -> UnivPhrase ;  -- if x,y : A then
\end{verbatim}

This includes document structure categories, \codeword{Title}, \codeword{Label},
\codeword{Paragraph}, \codeword{Definition}, \codeword{Conclusion}, etc. While
these may resembling a module system in ways, they also reflect a different
semantic sense than Agda's module system, which gives the programmer greater
control of handling software complexity. \codeword{ConclusionPhrase} reflects
what Agda's typechecker infers and is displayed to the user, and is therefore
redundant from the programmers perspective.

We have implemented Agda representation, which we compare with the rendered
latex, as well as the cubicalTT syntax in theappendix \ref{comparison}

\subsubsection{Ideas for resolution}





% -- Proof using isPropIsContr. This is slow and the direct proof below is better
% -- Direct proof that computes quite ok (can be optimized further if
% -- necessary, see:
% q-- HTTPSqqq://github.com/mortberg/cubicaltt/blob/pi4s3_dimclosures/examples/brunerie2.ctt#L562


