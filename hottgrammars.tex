\subsection{Ranta's HoTT Grammar}

In 2014, Ranta gave an unpublished talk at the Stockholm Mathematics Seminar
\cite{aarneHott}. Fortunately the code is available, although many of the design
choices aren't documented in the grammar. This project aimed to provide a
translation like the one desired in our current work, but it took a real piece
of mathematics text as the main influence on the design of the abstract syntax.

This work took a page of text from Peter Aczel's book which more or less goes
over standard HoTT definitions and theorems. The grammar allows the translation
of the latex document in English to the same document in French, and to a pidgin
logical language. The central motivation of this grammar was to capture entirely
``real" natural language mathematics, i.e. that which was written for the
mathematician. Therefore, it isn't reminiscent of the slender abstract syntax
the type theorist adores, and sacrificed ``syntactic completeness" for
``semantic adequacy". This means that the abstract syntax is much larger and
very expressive, but it no longer becomes easy to reason about and additionally
quite ad-hoc. Another defect is that this grammar overgenerates, so producing a
unique parse from the PL side would require a significant amount of refactoring.
Nonetheless, it is presumably possible to carve a subset of the
GF HoTT abstract file to accommodate an Agda program, but one encounters rocks
as soon as one begins to dig.

In \autoref{fig:R1} one can see different syntactic presentations of a notion of
\emph{contractability}, that a space is deformable into a single point, or that a Type
is actually inhabited by a unique term. Some rendered latex taken verbatim from
Ranta's test code, compared with the translated pidgin logic code (after
refactoring of Ranta's linearization scheme) and an Agda program. We see that it was
fairly easy to get the notation for our cubicalTT grammar [ref cubicaltt].
When parsing the logical form, unfortunately, the grammar is incredibly ambiguous.

\input{latex/ContrClean}

To extend this grammar to accommodate a chapter worth of material, let alone a
book, will not just require extending the lexicon, but encountering other
syntactic phenomena that will further be difficult to compress when defining
Agda's concrete syntax. This demonstrates that to design a grammar prioritizing
\emph{semantic adequacy} and subsequently trying to incorporate \emph{syntactic
completeness} becomes a very difficult problem. Depending on the application of
the grammar, the emphasis on this axis is most assuredly a choice one should
consider up front.

The next grammar, taking an actual programming language
parser in Backus-Naur Form Converter (BNFC), GFifying it, and trying to use the
abstract syntax to model natural language, gives in some sense a dual challenge,
where the abstract syntax remains simple as in our dependently typed grammar,
but its linearizations become increasingly complex, especially when generating
natural language.

\subsection{cubicalTT Grammar}

Cubical type theories arose out of the desire to give a complete computational
interpretation to HoTT, whereby nonviolence would become a theorem rather than
an axiom \cite{cohen:hal-01378906}. The utility of this is that canonicity, the
property of an expression having a irreducible normal form, is satisfied for all
expressions. Univalence, by introducing a type without computational behavior,
means that the constructivist using Agda will be able to define terms which
don't normalize.

The origin of cubical, looking beyond simplicial models of type theory to
cubical categories instead \cite{bezem2017univalence}, gave a blueprint for a
totally new type theory which natively supports proving functional
extensionality, which is a especially important for mathematicians. The ideas of
cubical became the origin for a new series of proof assistants, cubical [cite
https://github.com/simhu/cubical] and cubicaltt [cite
https://github.com/mortberg/cubicaltt], and Cubical Agda \cite{cubicalAgda}, as
well as other in originating from Robert Constables disciples in the NuPrl
tradition [cite redprl, redtt, jonprl]. cubicalTT, which was relatively
complete, had an unambiguous BNFC grammar, more or less represents a kernel of
Agda with cubical primitives. This final grammar, which we don't as cubicalTT,
took the actual cubicalTT grammar and GFified the subset which is in the
intersection with vanilla Agda. Extending our GF version to include cubical
primitives would facilitate the extension of the work to Cubical Agda, and we
hope future endeavors will go in this direction. Cubical Agda
supports Higher Inductive Types natively and is capable of all types of new
constructions [cite stuff] not mentioned in the HoTT book, but is also
incredibly experimental, with large changes to the standard library constantly
underway as in [refer intro].

Our grammar for vanilla dependent $\Pi$-types [refer earlier section] was actually
a subset of the current cubicalTT abstract syntax. We give a brief sketch of the
algorithm to go between a BNFC grammar and a GF grammar. BNFC essentially
combines the abstract and concrete syntax, enabling a hierarchy of numbered
expressions \term{ExpN} to minimize use of parentheses. So, given m names and
choosing $Name_i$, with the accompanying rule :

$$Name_i.\; ReturnCat_{i_n} ::= s^0_{i}\;C^0_{i_0}\;...\;C^{n-1}_{i_{n-1}}\;s^n_{i}\;;$$

where string $s^i_j$ may be empty and the $k$ in the $i^{th}_k$ subscript represents the 
precedence number of a category. These precedences are indicated with a
\term{Coercions N} keyword in BNFC. We can produce the following in GF.

$$cat\; Name_i\; \bigcap\{ReturnCat_i,C^0,..., C^{n-1}\}\;;$$
$$fun\; Name_i\:{:} C^0 \rightarrow ... \rightarrow C^{n-1} \rightarrow ReturnCat_i $$
$$lincat \: \bigcap\{ReturnCat_i,C^0,..., C^{n-1}\}\;; = TermPrec$$
$$lin \; Name_i\;c^0\;... \;c^n = mkPrec(i_n,(s^0_{i}\texttt{++}usePrec(i_0+1,c^0)\texttt{++}...\texttt{++}usePrec(i_{n-1}+1,c^{n-1})\texttt{++}s^n_{i})) ;$$

where $c^j \in C^j \; \forall i,j$, and \term{usePrec} and \term{mkPrec} come
from the RGL, as seen earlier. We also note that some \term{lincat} might
actually just be strings (or something else), for it is only when a precedence
is observed that the \codeword{TermPrec} is applicable. The use of
\term{usePrec} is only applicable when $i_k$ isn't empty. Additionally, this
doesn't account for the fact that already some categories may have been
witnessed in which case we want to intersect over the whole set of rules at
once. We reiterate the examples from the simply typed lambda calculus. The BNFC
code results in the GF code immediately below.

\begin{verbatim}
--BNFC
Lam. Exp  ::= "\\" [PTele] "->" Exp ;
Fun. Exp1 ::= Exp2 "->" Exp1 ;
-- GF
cat Exp ; PTele ;
fun
  Lam : [PTele] -> Exp -> Exp ;
  Fun : Exp -> Exp -> Exp ;
lincat Exp = TermPrec ; [PTele] = Str ;
lin 
  Lam pt e = mkPrec 0 ("\\" ++ pt ++ "->" ++ usePrec 0 e) ;
  Fun = mkPrec 1 (usePrec 2 x ++ "->" ++ usePrec 1 y) ;
\end{verbatim}

This more or less elaborates exactly how to implement a programming language
with unambiguous parsing in GF. There is also a simple means of translating
lists, including BNFC's \term{separator} and \term{terminator} keywords during
the linearization process. Finally, there is a custom \term{token} keyword, and
this is perhaps the most important feature absent in GF.
Because BNFC generates Haskell code reminiscent of the PGF embedding, it would
also be possible to translate the trees directly, if parsing complexity with GF
was found to be slower than BNFC.

Most interestingly is to look at what is
absent in BNFC, namely, the ability to add records and paremeters into the
linearization types generally, although these GF features are implicitly used to
encode precedence. For one could add unique categories in GF $Exp_1,...,Exp_n$, but this would
clutter the abstract syntax with information which isn't \emph{semantically}
relevant. And while the Haskell code generated by BNFC for cubicalTT is sent through a
resolver to the \emph{actual} abstract syntax used by the type-checker and
evaluator, the fact that it parses the concrete syntax into an appropriate
intermediary form is enough for our purposes. 

\subsubsection{Difficulties}

\subsection{Comparing the Grammars}

\subsubsection{Ideas for resolution}



-- Proof using isPropIsContr. This is slow and the direct proof below is better

isPropIsEquiv' : (f : A → B) → isProp (isEquiv f)
equiv-proof (isPropIsEquiv' f u0 u1 i) y =
  isPropIsContr (u0 .equiv-proof y) (u1 .equiv-proof y) i

-- Direct proof that computes quite ok (can be optimized further if
-- necessary, see:
q-- HTTPSqqq://github.com/mortberg/cubicaltt/blob/pi4s3_dimclosures/examples/brunerie2.ctt#L562




% Example expressions the grammar can parse are seen below, which have been
% verified by hand to be isomorphic to the corresponding cubicaltt BNFC trees:

% \begin{verbatim}

% data bool : Set where true | false
% data nat : Set where zero | suc ( n : nat )
% caseBool ( x : Set ) ( y z : x ) : bool -> Set = split false -> y || true -> z
% indBool ( x : bool -> Set ) ( y : x false ) ( z : x true ) : ( b : bool ) -> x b = split false -> y || true  -> z
% funExt  ( a : Set )   ( b : a -> Set )   ( f g :  ( x : a )  -> b x )   ( p :  ( x : a )  -> ( b x )   ( f x ) == ( g x )  )  : (  ( y : a )  -> b y )  f == g = undefined
% foo ( b : bool ) : bool = b

% \end{verbatim}

% [Todo] add use cases

