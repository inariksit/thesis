\section{Previous Work}

There is a story that at some point, Göran Sundholm and Per Martin-Löf were
sitting at a dinner table, dicsussing various questions of interest to the
respective scholars, and Sundholm presented Martin-Löf with the problem of
Donkey Sentences in natural language semantics, those analogous 'Every man who
owns a donkey beats it'. This had been puzzling to those in the Montague
tradition, whereby higher order logic didn't provide facile ways of interpreting
these sentences. Martin-Löf apparently then, using his dependent type
constructors, provided an interpretation of the donkey sentence on the back of
the napkin. This is perhaps the genesis of dependent type theory in natural
language semantics. The research program was thereafter taken up by Martin-Löf's
student Aarne Ranta \cite{ranta1994type}, bled into the development of GF, and
has now in some sense led to this current work.

The prior exploration of these interleaving subjects is vast, and we can only
sample the available literature here. Indeed, there are so many approaches that
this work should be seen in a small (but important) case in the context of a
deep and broad literature \cite{surveyLang}. Acquiring expertise in such a
breadth of work is outside the scope of this thesis. Our approach, using
GF ASTs as a basis language for Mathematics and the logic the mathematical
objects are described in, is both distinct but has many roots and
interconnections with the remaining literature. The success of finding a
suitable language for mathematics will obviously require a comparative analysis
of the strengths and weaknesses in the goals in such a vast bibliography. 
 How the GF approach compares with this long merits careful consideration and
 future work.

It will function of our purpose, constrained by the limited scope of this work,
to focus on a few important resources.

\subsection{Ranta}

The initial considerations of Ranta were both oriented towards the language of
mathematics \cite{ranta93}, as well as purely linguistic concerns
\cite{ranta1994type}. In the treatise, Ranta explored not just the many avenues
to describe NL semantic phenomena with Dependent Types, but, after concentrating
on a linguistic analysis, he also proposed a primitive way of parsing and
sugaring these dependently typed interpretations of utterances into the strings
themselves - introducing the common nouns as types idea which has been since
seen great interest from both type theoretic and linguistic communities
\cite{luoCNs}. Therefore, if we interpret the set of men and the set of donkeys
as types, e.g. we judge $\vdash man \; {:} {\rm type}$ and $\vdash donkey \; {:}
{\rm type}$ where ${\rm type}$ really denotes a universe, and ditransitive verbs
``owns'' and ``beats'' as predicates, or dependent types over the CN types, i.e.
$\vdash owns \; {:} man \rightarrow donkey \rightarrow {\rm type}$ we can
interpret the sentence ``every man who owns a donkey beats it'' in DTT via the
following judgment :

\[\Pi z : (\Sigma x : man. \; \Sigma y : donkey. \; owns(x,y)). \; beats(\pi_1z,\pi_1(\pi_2z))\]

We note that the natural language quantifiers, which were largely the subject of
Montague's original investigations \cite{Montague1973}, find a natural
interpretation as the dependent product and sum types, $\Pi$ and $\Sigma$,
respectively. As type theory is constructive, and requires explicit witnesses
for claims, we admit the behavior following semantic interpretation : given a
man $m$, a donkey $d$ and evidence $m-owns-d$ that the man owns the donkey, we
can supply, via the term of the above type applied to our own tripple
$(m,d,m-owns-d)$ , evidence that the man beats the donkey, $beats(m,d)$ via
$pi_1$ and $pi_2$, the projections, or $\Sigma$ eliminators.

In the final chapter of \cite{ranta1994type}, $Sugaring and Parsing$, Ranta
explores the explicit relation, and of translation between the above logical
form and the string, where he presents a GF predecessor in the Alfa proof
assistant, itself a predecessor of Agda. To accomplish this translation he
introduces an intermediary , a functional phrase structure tree, which later
becomes the basis for GFs abstract syntax.  What is referred to as ``sugaring''
later changes to ``linearization''.

Soon thereafter, GF became a fully realized vision, with better and more
expressive parsing algorithms \cite{ljunglof2004expressivity} developed in
Göteborg allowed for sugaring that can largely accommodate morphological
features of the target natural language \cite{rantaForsberg}, the translation
between the functional phrase structure (ASTs) and strings \cite{ranta_2004}.

Interestingly, the functions that were called $ambiguation : MLTT \to \{Phrase\
Structure\}$ and $interpretation : \{Phrase Structure\} \to MLTT$ were absorbed
into GF by providing dependently typed ASTs, which allows GF not just to parse
syntactic strings, but only parse semantically well formed, or meaningful
strings. Although this feature was in some sense the genesis that allowed GF to
implement the lingusitic ideas from the book \cite{rantaTT}, it has remained
relatively limited in terms of actual GF programmers using it in their day to
day work. Nonetheless, it was intriguing enough to investigate briefly during
the course of this work as one can implement a programming language grammar that
only accepts well typed programs, at least as far as they can be encoded via
GF's dependent types \cite{warrickHarper}. Although GF isn't designed with
TypeChecking in mind explicity, it would be very interesting to apply GF
dependent types in the more advanced programming languages to filter parses of
meaningless strings.

While the semantics of natural language in MLTT is relevant historically, it is
not the focus of this thesis. Its relevance comes from the fact that all these
ideas were circulating in the same circles - that is, Ranta's writings on the
language of mathematics, his approach to NL semantics, and their confluence
among other things, with the development of GF. This led to the development of a
natural language layer to Alfa \cite{alfaGF}, which in some sense can be seen as
a direct predecessor to this work. In some sense, the scope of work seeks to
recapitulate what was already done in 1998 - but this was prior to both GF's
completion, and Alfa's hard fork to Agda.

\subsection{Mohan Ganesalingam}


\begin{displayquote}

there is a considerable gap between what mathematicians claim is true and what
they believe, and this mismatch causes a number of serious linguistic problems

\end{displayquote}

Perhaps the most substantial analysis of the linguistic perspective on
written mathematics comes from Ganesalingam \cite{ganesalingam2013language}.
Not only does he pick up and reexamine much of Ranta's early work, but he
develops a whole theory for how to understand with the language mathematics from
a formal point of view, additionally working with many questions about the
foundation of mathematics. His model which is developed early in the treatise
and is referenced 
throughout uses Discourse Representation Theory \cite{kamp2011discourse}, to
capture anaphoric use of variables. While he is interested in analyzing
language, or goal is to translate, because the meaning of an expression is
contained in its set of formalizations, so GF is more of just a tool in the
pipeline rather than an actual infrastructure through which to dissect the various
nuances of human speech.


"
meaningful statements in some underlying logic. If it was pointed out that
a particular sentence had no translation into such a logic, a mathematician
would genuinely feel that they had been insufficiently precise. (The actual
translation into logic is never performed, because it is exceptionally laborious;
"

"
mathematics has a normative notion of what its content should look like; there is no
analogue in natural languages.
"

1.2.3 full adaptivity


"
From a linguistic perspective, the formal mode is more novel and interesting
because it is restricted enough to describe completely, both in terms of syntax
and semantics. By contrast, the informal mode seems as hard to describe as
general natural language. We will therefore look only at mathematics in the
formal mode.
"


Section 2

"
The primary function of symbolic mathematics is to abbreviate material
that would be too cumbersome to state with text alone. Thus a sentence
"

"
Because symbolic material functions primarily in an abbreviative capacity,
symbolic mathematics tends to occur inside textual mathematics rather than
vice versa. Thus mathematical texts are largely composed out of textual
"

"
adaptivity
a phenomenon that is much more remarkable than the use of symbols. Math-
ematical language expands as more mathematics is encountered. The kind of
"

"
Thus definitions always contain enough information to fully specify the
semantics of the material being defined.
"

"
As a result, textual mathematics predominantly
uses the third person singular and third person plural, to denote individual
"

"
verbs, typically to refer to the mutual intent of the author and reader.
Working mathematicians treat mathematical objects as if they were Pla-
tonic ideals, timeless objects existing independently of the physical world. The
"

"
The limited variation in person and tense means that inflectional morphol-
gy plays only a small part in mathematical language. The only morphological
"

"The syntax of textual mathematics also exhibits relatively limited variation."


this means that textual mathematics can be effectively captured by a context-
free grammar (in the sense of (Jurafsky and Martin, 2009, p. 387)).

In contrast to the morphology and syntax of textual mathematics, its
lexicon is remarkably varied. As we have noted above, the mechanism of

no tense or events
no intesnionality
no modality

"
usual. To a first approximation, mathematics does not exhibit any pragmatic
phenomena: the meaning of a mathematical sentence is merely its composition-
ally determined semantic content, and nothing more. In order to state this point
"


"
Due to the absence of pragmatic phenomena, phenomena which are some-
times analysed as semantic and sometimes analysed as pragmatic can be
treated as being purely semantic where they occur in mathematics, i.e. they
can be analysed in purely truth-conditional terms. This applies particularly
to presuppositions, which play an important role in mathematics. Because
"

"
Thus, in some intuitive sense, syntax is dependent on the types of expres-
sions in a way that does not occur in existing formal languages. As we will
show in §3.2 and Chapter 4, this notion of type is too semantic itself to be
formalised in syntactic terms. In other words, the type of an expression is too
closely related to what that expression refers to for purely syntactic notions
of type to be applicable.
"

"
most ambiguity in mathematics is not noticed by mathematicians, just as the extensive ambi-
guity in natural languages is “simply not noticed by the majority of language
"

"
in an extremely compact manner. In essence, they serve as a mathematical
alternative to anaphor. They cannot be eliminated precisely because anaphor
"

reanalysis

Chapter 7 pg 181

be equal as distinct. In both cases, a disparity between the way we think
about mathematical objects and the way they are formally defined causes
our linguistic theories to make incorrect predictions. In order to obtain the
correct predictions about language, we need to make sure that the formal
situation matches actual usage.

mal proofs are provided; and the cycle repeats. Thus informal mathematics
changes over the centuries. 187

% my idea
engineers are motivated by needs and desires (emirical, descriptive,
practial) , whereas mathematicians are much more idealistic in their pursuits,
almost comparable to a stances on religious scripture

mathematics developing over time is natural, the more and deeper we dig into the
ground, the more we develop refinements of what kind of tools we are using,
develop better iterations of the same tools (or possibly entirely new ones) as
well as knowledge about the ground in which we are digging (these are adjoining)

in some sense the library of babel problem, whereby we dont just discover
predefined ideas by randomly sampling bags of words, but we have to work with
hard labor, sweat, and tears, to imbue the sentences of mathematics with meaning
that makes them descriptive, that there is some kind of internal, but
distributed, mental process which is mirror whats on paper (and the 'reality' it
describes)

relate this to HoTT as a perfect 'case study' in the foundations of mathematics


\subsection{other authors}

\begin{displayquote}
QED is the very tentative title of a project to build a computer system that effectively represents all important mathematical knowledge and techniques.
\cite{godel1994qed} 
\end{displayquote}

The ambition of the QED Manifesto, with formalization and informalization of
mathematics being one subset, is probably impossible. The myriad attempts
at formalization and informalization are too much to compress here - a survey
and comparison of these ideas is unfortunately unavailable. We recount some of
them briefly.

The Naproche project (Natural language Proof Checking) is a CNL for studying the
language of mathematics by using Proof Representation Structures, a mutated form
of Discourse Representation Structures \cite{cramer2009naproche}. A central
goal of Naproche is to develop a controlled natural language (CNL), based off FOL, for
mathematics texts. It parses a theorem from the CNL into fully formal
statement, and then comes with a proof checking back-end to allow verification,
where it uses an Automated Theorem Prover (ATP) to check for correctness.
While the language is quite ``natural looking", it doesn't offer the same
linguistic flexibility as our GF approach and aspirations.

Mizar is a system attempting to be a formal language,which mathematicians can
use to express their results, and a database \cite{rudnicki1992overview}. It is
based off Tarski-Grothendeick set theory, and allows for correctness checking of
articles. It was originally developed concurrent to Martin-Löf's work in 1973,
and so much of the interest in types instead of sets couldn't be anticipated.
The focus Mizar on syntax resembling mathematics was pioneering, nonetheless, it
uses clumsy references and looks unreadable to those without expertise. Mizar
has a journal devoted to results in it, \emph{Formalized Mathematics}, and
offers a large library of known results. Additionally, it has inspired
iterations for other vernacular proof assistants, like Isabelle's Intelligible semi-automated
reasoning (Isar) extension \cite{wenzel2004isabelle}.

Subsequently, in \cite{mlTrans}, the authors take a corpus of parallel Mizar proofs natural
language proofs with latex, and seek to \emph{autoformalize} natural language
text with the intention of, in the future, further elaboration into an ITP.
This work uses traditional language models from the machine learning community, and analyze
the results. They were able to see some results, but nothing that as of yet can
be foreseen to general use.  Interestingly, a type elaboration mechanism in some
of their models was shown to bolster results.

Formalization seems more feasible with machine learning methods than
informalization , partially because tactics like ``hammer" in Coq for example,
are capable of some fairly large proofs \cite{czajka2018hammer} . Nonetheless,
for the Agda developer this isn't yet very relevant, and it's debatable whether
it would even be desirable. Voevodsky, for example, was apparently skeptical of
the usefulness of automated theorem proving for much of mathematics, as are many
mathematicians (although this is certainly changing).

The Boxer system, a CCG parser \cite{bos-etal-2004-wide} which allows English
text translation into FOL. However, it is not always correct, and dealing with
the language of mathematics will present obstacles. 

In \cite{proofFrom} the authors test the informalization. Despite working with
Coq, the the authors poignantly distinguish between proof scripts, sequences of
tactics, and proof objects, and focus on natural deduction proofs. Since Coq is
equipped with notions of Set, Type, and Prop, their methods make distinguishing
between these possibly easier. This work only focuses on linearization of trees,
and GF's pretty printer is likely superior to any NL generation techniques
because of help from the RGL. The complexity of the system also made it
untenable for larger proofs - nonetheless, it serves as an important prelude to
many of the subsequent GF developments in this area.

There are many other examples exploring the natural language and theorem prover
boundary. It should be noted that GF's role in this space is primitive, but it
does offer the advantage of being interfaced with many natural languages, and in
programming languages too, including the syntax of these systems. We also hope
other PL developers will and use , like the Grammatical Logical Inference
Framework (GLIF), which uses GF as a front-end for the Meta-Meta-Theory
framework \cite{schaefer2020glif}.





--- For conclusion



The quest for computers doing mathematics for us, or at least helping is, has
seen many bifurcations since the birth of computer science. I believe doing
mathematics is impossible, but computers certainly do help.