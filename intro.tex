\section{Introduction}
\label{sec:intro}

The central concern of this thesis is the syntax of mathematics, programming
languages, and their respective mutual influence, as conceived and practiced by
mathematicians and computer scientists.  From one vantage point, the role of
syntax in mathematics may be regarded as a 2nd order concern, a topic for
discussion during a Fika, an artifact of ad hoc development by the working
mathematician whose real goals are producing genuine mathematical knowledge.
For the programmers and computer scientists, syntax may be regarded as a
matter of taste, with friendly debates recurring regarding the use of
semicolons, brackets, and white space.  Yet, when viewed through the lens of
the propositions-as-types paradigm, these discussions intersect in new and
interesting ways.  When one introduces a third paradigm through which to
analyze the use of syntax in mathematics and programming, namely linguistics, I
propose what some may regard as superficial detail, indeed becomes a central
paradigm raising many interesting and important questions. 

\subsection{Beyond Computational Trinitarianism}

\begin{displayquote}

The doctrine of computational trinitarianism holds that computation manifests
itself in three forms: proofs of propositions, programs of a type, and mappings
between structures. These three aspects give rise to three sects of worship:
Logic, which gives primacy to proofs and propositions; Languages, which gives
primacy to programs and types; Categories, which gives primacy to mappings and
structures.\emph{Robert Harper} \cite{harperTrinity}
\end{displayquote}

We begin this discussion of the three relationships between three respective
fields, mathematics, computer science, and logic. The aptly named 
trinity, shown in \autoref{fig:M1}, are related via both \emph{formal} and \emph{informal}
methods. The propositions as types paradigm, for example, is a heuristic. Yet
it also offers many examples of successful ideas translating between the domains.
Alternatively, the interpretation of a Type Theory(TT) into a category theory is
completely \emph{formal}.

\begin{figure}[H]
\centering
\begin{tikzcd}
                                                                            &  &  & Logic \arrow[llldddd, "Denotational\ Semantics" description] \arrow[rrrdddd, "Include\ Terms" description] &  &  &                                                                                                       \\
                                                                            &  &  &                                                                                                            &  &  &                                                                                                       \\
                                                                            &  &  &                                                                                                            &  &  &                                                                                                       \\
                                                                            &  &  &                                                                                                            &  &  &                                                                                                       \\
Math \arrow[rrruuuu, "Embedded\ in\ FOL", bend left] \arrow[rrrrrr, "ITP"'] &  &  &                                                                                                            &  &  & CS \arrow[llllll, "Denotational\ Semantics", bend left] \arrow[llluuuu, "Remove\ Terms"', bend right]
\end{tikzcd}
\caption{The Holy Trinity} \label{fig:M1}
\end{figure}

We hope this thesis will help clarify another possible dimension in this
diagram, that of Linguistics, and call it the ``holy tetrahedron". The different
intellectual communities represented by the three subjects of the trinity also
resemble religions in their own right, convinced that they have a canonical
perspective on foundations and the essence of mathematics. Questioning the holy
trinity is an act of a heresy, and it is the goal of this thesis to be heretical
by including a much less well understood perspective which provides additional
challenges and insights into the trinity.

\begin{figure}[H]
\centering
\begin{tikzcd}
     &  &  & Logic                                                                                                                     &  &  &            \\
     &  &  &                                                                                                                           &  &  &            \\
     &  &  & Linguistics \arrow[uu, "Montague\ Semantics"'] \arrow[llldd, "Distributional\ Semantics"'] \arrow[rrrdd, "TT\ Semantics"] &  &  &            \\
     &  &  &                                                                                                                           &  &  &            \\
Math &  &  &                                                                                                                           &  &  & CS\ (MLTT)
\end{tikzcd}
\caption{Formal Semantics} \label{fig:M2}
\end{figure}

One may see how the trinity give rise to \emph{formal} semantic interpretations
of natural language in \autoref{fig:M2}. Semantics is just one possible
linguistic phenomenon worth investigating in these domains, and could be
replaced by other linguistic paradigms. This thesis is alternatively concerned
with syntax.

Finally, as in \autoref{fig:M3}, we can ask : how does the trinity embed into
natural language? These are the most \emph{informal} arrows of tetrahedron, or
at least one reading of it. One can analyze mathematics using linguistic
methods, or try to give a natural language justification of Intuitionistic Type
Theory (ITT) using Martin-Löf's meaning explanations.

\begin{figure}[H]
\centering
\begin{tikzcd}
                                                &  &  & Logic \arrow[dd, "Embedding"] &  &  &                               \\
                                                &  &  &                               &  &  &                               \\
                                                &  &  & Linguistics                   &  &  &                               \\
                                                &  &  &                               &  &  &                               \\
Math \arrow[rrruu, "Language\ Of\ Mathematics"] &  &  &
&  &  & CS\ (MLTT) \arrow[llluu, "Meaning\ Explanations"]
\end{tikzcd}
\caption{Interpretations of Natural Language} \label{fig:M3}
\end{figure}

In this work, we will see that there are multiple GF grammars which model some
subset of each member of the trinity. Constructing these grammars, and it is
important to ask how they can be used in applications for mathematicians,
logicians, and computer scientists. Therefore we hope this attempt at giving the
language of mathematics, in particular how propositions and proofs are expressed
and thought about in that language, a stronger foundation.

\subsection{The Goal before Us }
\begin{displayquote}
Treating propositions as types is definitely not in the way of thinking of
ordinary mathematician, yet it is very close to what he actually does. 
\emph{N. G. de Bruijn} \cite{deBruijn1983}.
\end{displayquote}

This thesis seeks to provide an abstract framework to determine whether two
lingusitically nuanced presenations mean the same thing via their syntactic
transformations. Obviously these meanings are not resolvable in any kind of
absolute sense, but at least from a translational sense. These syntactic
transformations come in two flavors : parsing and linearization, and are
natively handled by a Logical Framework (LF) for specifying grammars :
Grammatical Framework (GF).

The type-checker, a language's mechanism of ensuring that programs satisfy the
specification of their types, is incredibly useful: it delegates the work of
verifying that a proof is correct, that is, the work of judging whether a term
has a type, to the computer. While its of practical concern is immediate to any
exploited grad student grading papers late on a Sunday night, its theoretical
concern has led to many recent developments in modern mathematics. Thomas Hales
solution to the Kepler Conjecture was seen as unverifiable by those reviewing
it, and this led to Hales outsourcing the verification to Interactive Theorem
Provers (ITPs) HOL Light and Isabelle. This computer delegated verification
phase led to many minor corrections in the original proof which were never
spotted due to human oversight.

Fields medalist Vladimir Voevodsky had the experience of being told one day
his proof of the Milnor conjecture was fatally flawed. Although the leak in the
proof was patched, this experience of temporarily believing much of his life's
work invalidated led him to investigate proof assintants as a tool for future
thought. Indeed, this proof verification error was a key event that led to the
Univalent Foundations
Project~\cite{theunivalentfoundationsprogram-homotopytypetheory-2013}.

While Agda and other programming languages are capable of encoding definitions,
theorems, and proofs, they have so far seen little adoption. In some cases they
have been treated with suspicion and scorn by many mathematicians. This isn't
entirely unfounded : it's a lot of work to learn Agda,
software updates may cause proofs to break, and the inevitable imperfections of
software are instilled in these tools . Besides, Martin-Löf Type Theory,
the constructive foundational project which underlies these proof assistants, is
often misunderstood by those who dogmatically accept the law of the excluded
middle as the word of God.

It should be noted, the constructivist rejects neither the law of the excluded
middle, $\phi \or \neg \ph$. She merely observes them, and admits its handiness
in certain situations. Excluded middle is indeed a helpful tool - many important
results rely on it. The type theorist's contention is that it should be avoided
whenever possible - proofs which don't rely on it, or it's corollaries like
proof by contradction, are much more amenable to formalization in systems with
decidable type checking. Zermelo-Fraenkel Set Theory with the axiom of choice,
ZFC, while serving the mathematicians of the early 20th century, is lacking when
it comes to the higher dimensional structure of n-categories.

What ITPs give the mathematician is confidence that her work is correct, and
even more importantly, that the work which she takes for granted and references
in her work is also correct. Foundational details aside, this thesis is meant to
provide insight into one piece, namely in the space of syntax, of a blueprint
for what many hope to be a reformation regarding how mathematics is practiced.

We don't insist a mathematician relinquish the beautiful language she has come
to love in expressing her ideas. Rather, we asks her to make a hypothetical
compromise for the time being, and use a Controlled Natural Language (CNL) to
encode key developments in her work. In exchange she may get some of the
confidence that Agda provides. Not only that, if adopted at scale, she will able
to search through a library to see who else has possibly already postulated and
proved her conjecture. A version of this grandiose vision is explored in The
Formal Abstracts Project \cite{halesCNL}, and it should practically motivate
part of our work.

Practicalities aside, this work also attempts to offer a nuanced philosophical
perspective on the matter by exploring why translation of mathematical language,
despite it's seemingly structured form, is difficult. A pragmatic treatment of
the language of mathematics is the golden egg if one wishes to articulate the
nuance in how the notions proposition, proof, and judgment are understood by
humans, and how their translation can really take place. This distant goal
should be prefaced with a semantic study of mathematics, which itself needs a
syntactic basis. We hope that the treatment of syntax in this thesis, while a
long ways away from giving a pragmatic account of mathematics, will help pave
the way there.

\input{perspectives}